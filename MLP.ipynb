{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "X_train = np.concatenate((mnist.train.images, mnist.validation.images))\n",
    "y_train = np.concatenate((\n",
    "            np.asarray(mnist.train.labels, dtype=np.int32),\n",
    "            np.asarray(mnist.validation.labels, dtype=np.int32),\n",
    "          ))\n",
    "X_test = mnist.test.images\n",
    "y_test = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ = X_train.reshape(-1, 784)\n",
    "y_train_ = np.eye(10)[y_train]\n",
    "X_test_ = X_test.reshape(-1, 784)\n",
    "y_test_ = np.eye(10)[y_test]\n",
    "X_train_.shape, y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, hparams):\n",
    "        self.n_input = 784\n",
    "        self.n_classes = 10\n",
    "        self.n_hidden1 = 200\n",
    "        self.n_hidden2 = 200\n",
    "        self.learning_rate = hparams['learning_rate']\n",
    "        \n",
    "    def preprocess_input(self, x):\n",
    "        return x\n",
    "    \n",
    "    def build_model(self, input_layer):\n",
    "        with tf.variable_scope(\"layer1\"):\n",
    "            self.layer1 = tf.layers.dense(input_layer, self.n_hidden1, tf.nn.relu)\n",
    "        with tf.variable_scope(\"layer2\"):    \n",
    "            self.layer2 = tf.layers.dense(self.layer1, self.n_hidden2, tf.nn.relu)\n",
    "        with tf.variable_scope(\"logits_layer\"):\n",
    "            self.logits = tf.layers.dense(self.layer2, self.n_classes)\n",
    "            \n",
    "    def build_loss(self):\n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=self.labels, \n",
    "            logits=self.logits,\n",
    "            loss_collection=tf.GraphKeys.LOSSES\n",
    "        )\n",
    "        \n",
    "    def build_optimizer(self):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.optimizer = optimizer.minimize(\n",
    "            loss=self.loss, \n",
    "            global_step=tf.train.get_global_step(),\n",
    "            name='train_op'\n",
    "        )\n",
    "\n",
    "    def build_predictions_obj(self):\n",
    "        logits = self.logits\n",
    "        classes = tf.argmax(input=self.logits, axis=1, name=\"classes_tensor\")\n",
    "        probabilities = tf.nn.softmax(self.logits, name=\"softmax_tensor\")\n",
    "        \n",
    "        tf.add_to_collection('predictions', logits)\n",
    "        tf.add_to_collection('predictions', classes)\n",
    "        tf.add_to_collection('predictions', probabilities)\n",
    "        \n",
    "        self.predictions = {\n",
    "            \"logits\": logits,\n",
    "            \"classes\": classes,\n",
    "            \"probabilities\": probabilities\n",
    "        }\n",
    "        \n",
    "    def build_eval_metric(self):\n",
    "        self.eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(labels=self.labels, predictions=self.predictions[\"classes\"])\n",
    "        }\n",
    "        \n",
    "    def build_all(self):\n",
    "        self.build_model()\n",
    "        self.build_loss()\n",
    "        self.build_optimizer()\n",
    "        self.build_predictions_obj()\n",
    "        self.build_eval_metric()\n",
    "            \n",
    "    def get_estimator(self, mode):\n",
    "        estimator = None\n",
    "        self.build_predictions_obj()\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            estimator = tf.estimator.EstimatorSpec(mode=mode, predictions=self.predictions)\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            self.build_loss()\n",
    "            self.build_optimizer()\n",
    "            estimator = tf.estimator.EstimatorSpec(mode=mode, loss=self.loss, train_op=self.optimizer)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            self.build_eval_metric()\n",
    "            self.build_loss()\n",
    "            estimator = tf.estimator.EstimatorSpec(mode=mode, loss=self.loss, eval_metric_ops=self.eval_metric_ops)\n",
    "        return estimator\n",
    "    \n",
    "    def get_model(self, features, labels, mode):\n",
    "        \"\"\"\n",
    "        When using the Estimator API, features will come as a TF Tensor already.\n",
    "        \"\"\"\n",
    "        # Do pre-processing if necessary.\n",
    "        self.input_layer = self.preprocess_input(features[\"x\"])\n",
    "        self.labels = labels\n",
    "\n",
    "        # Define the model.\n",
    "        self.build_model(self.input_layer)\n",
    "        \n",
    "        # Build and return the estimator.\n",
    "        return self.get_estimator(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './mnist/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x124a2a898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "hparams = {'learning_rate': 0.001}\n",
    "model = Perceptron(hparams)\n",
    "classifier = tf.estimator.Estimator(model_fn=model.get_model, model_dir=\"./mnist/\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt-23613\n",
      "[]\n",
      "Tensor(\"logits_layer/dense/BiasAdd:0\", shape=(100, 10), dtype=float32)\n",
      "{'layer1/dense/kernel:0': array([[-0.01104958, -0.03149257,  0.0609542 , ...,  0.04887503,\n",
      "        -0.05664973,  0.00778133],\n",
      "       [-0.03988727, -0.0560302 , -0.0709151 , ..., -0.02928087,\n",
      "         0.05130166, -0.07581948],\n",
      "       [ 0.05992617,  0.02358893,  0.01766432, ...,  0.03194337,\n",
      "        -0.04137886, -0.02968797],\n",
      "       ...,\n",
      "       [-0.00962557, -0.06150879, -0.05601227, ..., -0.03184977,\n",
      "        -0.02179823,  0.03371893],\n",
      "       [ 0.05295402, -0.04876651,  0.07415543, ...,  0.05580209,\n",
      "         0.04050494, -0.06941249],\n",
      "       [-0.05708542,  0.05524662, -0.03389598, ...,  0.03212387,\n",
      "        -0.06944697,  0.03257002]], dtype=float32), 'layer1/dense/bias:0': array([-0.03311902, -0.14471869, -0.1002543 , -0.02374201, -0.01721681,\n",
      "       -0.04443753,  0.04729019, -0.1204375 ,  0.06492611,  0.07457326,\n",
      "       -0.13051437,  0.20195019, -0.00694241, -0.05435921, -0.0615164 ,\n",
      "       -0.281682  , -0.06439892, -0.12723564, -0.12199339,  0.07591756,\n",
      "        0.15622403,  0.00292117,  0.05217758,  0.07655474, -0.00087063,\n",
      "       -0.09814455, -0.021318  ,  0.07600338, -0.12191084,  0.0075237 ,\n",
      "        0.015504  , -0.11277445,  0.01906838,  0.15454742, -0.2501048 ,\n",
      "        0.05295547,  0.13423464, -0.0060253 ,  0.03524339,  0.03554297,\n",
      "       -0.00233773, -0.08682412, -0.19070244, -0.23528357,  0.01556841,\n",
      "        0.02184211,  0.06357921,  0.1024883 , -0.14207996, -0.0098196 ,\n",
      "        0.24104531,  0.06414191,  0.01587448, -0.07740874,  0.01679966,\n",
      "       -0.205904  ,  0.09572794,  0.12011979, -0.03666602, -0.1607297 ,\n",
      "        0.03449899, -0.07151773, -0.14488713,  0.04340551,  0.07608213,\n",
      "        0.10185873, -0.06036101, -0.0442534 ,  0.07638665, -0.03058627,\n",
      "        0.01391575,  0.17296103, -0.04996261, -0.19913666,  0.02317822,\n",
      "        0.06210525, -0.1017065 , -0.08691546,  0.09302536, -0.09492995,\n",
      "        0.1542731 , -0.04095481,  0.02271868, -0.12830167, -0.1485671 ,\n",
      "        0.03938167, -0.00782126,  0.07620216, -0.09490546,  0.01282945,\n",
      "        0.08829054, -0.04531834, -0.04562781, -0.04961753, -0.02701351,\n",
      "       -0.020785  ,  0.1649537 ,  0.04932218, -0.06720553, -0.02468906,\n",
      "        0.00152269, -0.07675207, -0.00780494,  0.18492067, -0.01023692,\n",
      "       -0.05649848, -0.01080585, -0.31464344, -0.03028631,  0.06579111,\n",
      "       -0.09153907, -0.05513784, -0.06475678,  0.07082436,  0.19510262,\n",
      "        0.04847256, -0.03764462, -0.14758606, -0.15402555, -0.16493434,\n",
      "        0.04595655, -0.01134669, -0.04957408,  0.05657583,  0.08710289,\n",
      "       -0.01848469, -0.05481118,  0.10703393,  0.09383498, -0.01714815,\n",
      "        0.04523566, -0.11156236, -0.09366577, -0.0054189 ,  0.04256636,\n",
      "       -0.01422399, -0.07390773,  0.15927197,  0.02142592, -0.11252059,\n",
      "        0.06805691,  0.03413121, -0.04929957, -0.16219315, -0.07205498,\n",
      "        0.04955179, -0.192842  , -0.03528204,  0.07782176, -0.02362558,\n",
      "        0.01081408,  0.03543288,  0.03403022,  0.01860582,  0.11495812,\n",
      "       -0.07930906,  0.0307288 , -0.07048459, -0.08475766, -0.02938383,\n",
      "       -0.05010784,  0.16851303,  0.00924837, -0.18575428, -0.01318346,\n",
      "        0.05958368, -0.06544635, -0.06051222, -0.10105639, -0.00687581,\n",
      "       -0.07684993, -0.09923361,  0.15844204, -0.13914241, -0.04526886,\n",
      "       -0.20045088,  0.06051726,  0.02802723, -0.1131601 , -0.0104011 ,\n",
      "       -0.18686496, -0.09173874,  0.15628007,  0.12032945,  0.01046313,\n",
      "        0.08636864, -0.01720509, -0.08132192,  0.01692501,  0.17351538,\n",
      "        0.0478318 ,  0.06502559, -0.14855483, -0.17502968,  0.06747219,\n",
      "       -0.07226989, -0.04339044, -0.0988025 , -0.04113051,  0.02528888],\n",
      "      dtype=float32), 'layer2/dense/kernel:0': array([[ 0.36614728,  0.20570529,  0.43382955, ...,  0.04797387,\n",
      "         0.15950726,  0.12226217],\n",
      "       [-0.2748479 , -0.13708465,  0.09163236, ..., -0.09663303,\n",
      "         0.22604555, -0.03382145],\n",
      "       [-0.07426097,  0.10903553,  0.0331796 , ...,  0.16236709,\n",
      "         0.02590821, -0.00506141],\n",
      "       ...,\n",
      "       [-0.02304759,  0.08417531, -0.2585045 , ...,  0.29080573,\n",
      "        -0.04504623,  0.07866569],\n",
      "       [-0.12516186, -0.14048299, -0.03712773, ..., -0.17104931,\n",
      "         0.16704078,  0.22409876],\n",
      "       [-0.02458612, -0.05308476, -0.03185492, ...,  0.1882122 ,\n",
      "         0.06765977, -0.12357881]], dtype=float32), 'layer2/dense/bias:0': array([-0.11558571,  0.09058169, -0.08315166,  0.00762999, -0.16256641,\n",
      "        0.059407  , -0.1373506 ,  0.0426135 , -0.0312861 , -0.14463444,\n",
      "       -0.15023448, -0.08333541, -0.04231432,  0.19471042,  0.0142457 ,\n",
      "       -0.07649462, -0.01618845, -0.01857645, -0.29718575,  0.22902396,\n",
      "       -0.07745504, -0.23306516, -0.08922563,  0.03657291, -0.2093008 ,\n",
      "        0.16374703, -0.11087141,  0.12805718, -0.08462771,  0.17364085,\n",
      "       -0.056656  ,  0.09128235,  0.23873408, -0.11281198,  0.08137991,\n",
      "       -0.08874943, -0.13552873, -0.10391781, -0.26756594,  0.14439584,\n",
      "        0.01074267, -0.06970428, -0.05385971,  0.0651945 , -0.1157181 ,\n",
      "        0.16931514, -0.12175827, -0.11115603,  0.29262903,  0.15616752,\n",
      "        0.07776079,  0.15312444, -0.05678846, -0.09356575, -0.23678136,\n",
      "       -0.0129044 , -0.08016449,  0.16388603,  0.1960282 , -0.28325146,\n",
      "       -0.04463179, -0.06474806,  0.08578083, -0.06515187, -0.11336424,\n",
      "       -0.08622395,  0.08868145,  0.0383815 ,  0.07696994, -0.2125071 ,\n",
      "       -0.13057317, -0.02810012, -0.01203863, -0.05937341, -0.10478991,\n",
      "       -0.12737718,  0.06074345,  0.00739238,  0.26480037,  0.01627936,\n",
      "       -0.12363675, -0.03366195,  0.03594215, -0.24935742, -0.1462084 ,\n",
      "       -0.12804866, -0.02483167,  0.07835744,  0.32254717,  0.15120572,\n",
      "        0.00095595,  0.18428066, -0.0727687 , -0.1690834 ,  0.1958138 ,\n",
      "        0.16420193,  0.05448308, -0.02664462,  0.0286763 ,  0.07195365,\n",
      "       -0.10945602,  0.02477953, -0.0919566 ,  0.13323328,  0.27585226,\n",
      "        0.0258294 , -0.07367961,  0.03373705,  0.09585148,  0.06673719,\n",
      "        0.09629219, -0.0510285 , -0.16241188,  0.01812022, -0.06864497,\n",
      "        0.1710781 , -0.09474307,  0.1731921 , -0.1519704 , -0.01157242,\n",
      "       -0.12081856,  0.02669615, -0.09567063, -0.02466096, -0.23062211,\n",
      "       -0.11162847, -0.19828905,  0.09101085, -0.19315381, -0.07647032,\n",
      "       -0.22543545,  0.11563712, -0.0340097 , -0.04299949,  0.17002748,\n",
      "       -0.13732259, -0.07152616, -0.04031312, -0.04644888,  0.18889   ,\n",
      "       -0.05620935, -0.21184102,  0.01752134, -0.16555694,  0.00249206,\n",
      "        0.28200766, -0.06412166, -0.14892483,  0.08408982,  0.23075381,\n",
      "        0.16549169,  0.10682657,  0.2555184 ,  0.13389541,  0.2711224 ,\n",
      "        0.13180871,  0.08103024, -0.11683288,  0.1400497 , -0.09993865,\n",
      "        0.05374884,  0.05420165, -0.15472963, -0.05620381, -0.07927939,\n",
      "        0.14253685, -0.24330932,  0.04850426, -0.24553543,  0.27023426,\n",
      "       -0.0107836 ,  0.06948327,  0.10763659, -0.0681743 , -0.06174065,\n",
      "       -0.12245593,  0.3248305 ,  0.06115509,  0.22190388, -0.02896852,\n",
      "        0.23314911,  0.18098153,  0.0605111 , -0.07447179, -0.08732665,\n",
      "       -0.12720776,  0.09987096, -0.06148928,  0.19787355,  0.05754415,\n",
      "       -0.07352457,  0.27132532, -0.03837418, -0.05203573,  0.02981596,\n",
      "        0.07617765,  0.06067104,  0.01260337, -0.1587489 , -0.04452389],\n",
      "      dtype=float32), 'logits_layer/dense/kernel:0': array([[-0.19427562, -0.18179384,  0.13797748, ...,  0.27703214,\n",
      "        -0.1689119 , -0.46528447],\n",
      "       [-0.40990975,  0.11680367,  0.07017844, ...,  0.03051657,\n",
      "         0.20286427,  0.02408654],\n",
      "       [-0.17962374,  0.06002008, -0.02140728, ..., -0.03910252,\n",
      "        -0.43263668,  0.14797798],\n",
      "       ...,\n",
      "       [-0.41982755,  0.07243734,  0.06284358, ...,  0.01127103,\n",
      "         0.11741241,  0.03728186],\n",
      "       [ 0.24894023, -0.28543746,  0.15427792, ...,  0.1968549 ,\n",
      "        -0.33184695, -0.46435913],\n",
      "       [ 0.1488057 , -0.31954363, -0.18749233, ...,  0.13422595,\n",
      "        -0.19182199,  0.18856211]], dtype=float32), 'logits_layer/dense/bias:0': array([-0.05765572, -0.18095502, -0.04650183, -0.05745185, -0.03124258,\n",
      "       -0.04452137, -0.13558002, -0.16484576,  0.42624772,  0.10935257],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ESTIMATOR WAY\n",
    "1- Server sends its 'input_fn()' defining the model and initial weights to clients \n",
    "    [yes]\n",
    "2- Clients create an estimator with the weights, train on their data, and send back the new weights to the server \n",
    "    [yes -- put weights in folder, create estimator with checkpoint, run fit on estimator, sends the latest checkpoint]\n",
    "3- As the server receives the new weights, it averages the weights; once done, it evaluates the model on a test set \n",
    "    [yes -- as weights are received we average them; once done, we load the model, assign the weights, save the model,\n",
    "    under new name, and run an eval on the test set]\n",
    "\n",
    "\n",
    "TRADITIONAL WAY\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# CLIENT\n",
    "def train_model(config):\n",
    "    \"\"\"\n",
    "    Loads the model and weights found in server-checkpoints/ (if found), trains using the hyperparameters \n",
    "    in config, then returns a list of new checkpoints after training. \n",
    "    \"\"\"\n",
    "    def make_weights_dict(sess, collection):\n",
    "        return {tensor.name:sess.run(tensor) for tensor in collection}\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #new_saver = tf.train.import_meta_graph(metagraph)\n",
    "        new_saver = tf.train.import_meta_graph(tf.train.latest_checkpoint('./mnist/') + '.meta')\n",
    "        try:\n",
    "            new_saver.restore(sess, tf.train.latest_checkpoint('./mnist/'))\n",
    "        except e:\n",
    "            # Couldn't load model.\n",
    "            print(\"Error...\")\n",
    "            raise e \n",
    "        \n",
    "        input = graph.get_collection('input_tensor:0')\n",
    "        print(input)\n",
    "        \n",
    "        logits, classes, probabilities = graph.get_collection('predictions')\n",
    "        print(logits)\n",
    "        \n",
    "        collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        print(make_weights_dict(sess, collection))\n",
    "        \n",
    "        for i in range(20000):\n",
    "            batch = mnist.train.next_batch(50)\n",
    "            train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "            if i % 100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "                print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            if i % 1000 == 0:\n",
    "                # test accuracy\n",
    "            \n",
    "\n",
    "        print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "# SERVER\n",
    "def aggregate_models(config):\n",
    "    \"\"\"\n",
    "    Loads the models found in updates/\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "train_model(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  beta1_power\n",
      "0.0\n",
      "tensor_name:  beta2_power\n",
      "5.4900008e-11\n",
      "tensor_name:  global_step\n",
      "23613\n",
      "tensor_name:  layer1/dense/bias\n",
      "[-0.03311902 -0.14471869 -0.1002543  -0.02374201 -0.01721681 -0.04443753\n",
      "  0.04729019 -0.1204375   0.06492611  0.07457326 -0.13051437  0.20195019\n",
      " -0.00694241 -0.05435921 -0.0615164  -0.281682   -0.06439892 -0.12723564\n",
      " -0.12199339  0.07591756  0.15622403  0.00292117  0.05217758  0.07655474\n",
      " -0.00087063 -0.09814455 -0.021318    0.07600338 -0.12191084  0.0075237\n",
      "  0.015504   -0.11277445  0.01906838  0.15454742 -0.2501048   0.05295547\n",
      "  0.13423464 -0.0060253   0.03524339  0.03554297 -0.00233773 -0.08682412\n",
      " -0.19070244 -0.23528357  0.01556841  0.02184211  0.06357921  0.1024883\n",
      " -0.14207996 -0.0098196   0.24104531  0.06414191  0.01587448 -0.07740874\n",
      "  0.01679966 -0.205904    0.09572794  0.12011979 -0.03666602 -0.1607297\n",
      "  0.03449899 -0.07151773 -0.14488713  0.04340551  0.07608213  0.10185873\n",
      " -0.06036101 -0.0442534   0.07638665 -0.03058627  0.01391575  0.17296103\n",
      " -0.04996261 -0.19913666  0.02317822  0.06210525 -0.1017065  -0.08691546\n",
      "  0.09302536 -0.09492995  0.1542731  -0.04095481  0.02271868 -0.12830167\n",
      " -0.1485671   0.03938167 -0.00782126  0.07620216 -0.09490546  0.01282945\n",
      "  0.08829054 -0.04531834 -0.04562781 -0.04961753 -0.02701351 -0.020785\n",
      "  0.1649537   0.04932218 -0.06720553 -0.02468906  0.00152269 -0.07675207\n",
      " -0.00780494  0.18492067 -0.01023692 -0.05649848 -0.01080585 -0.31464344\n",
      " -0.03028631  0.06579111 -0.09153907 -0.05513784 -0.06475678  0.07082436\n",
      "  0.19510262  0.04847256 -0.03764462 -0.14758606 -0.15402555 -0.16493434\n",
      "  0.04595655 -0.01134669 -0.04957408  0.05657583  0.08710289 -0.01848469\n",
      " -0.05481118  0.10703393  0.09383498 -0.01714815  0.04523566 -0.11156236\n",
      " -0.09366577 -0.0054189   0.04256636 -0.01422399 -0.07390773  0.15927197\n",
      "  0.02142592 -0.11252059  0.06805691  0.03413121 -0.04929957 -0.16219315\n",
      " -0.07205498  0.04955179 -0.192842   -0.03528204  0.07782176 -0.02362558\n",
      "  0.01081408  0.03543288  0.03403022  0.01860582  0.11495812 -0.07930906\n",
      "  0.0307288  -0.07048459 -0.08475766 -0.02938383 -0.05010784  0.16851303\n",
      "  0.00924837 -0.18575428 -0.01318346  0.05958368 -0.06544635 -0.06051222\n",
      " -0.10105639 -0.00687581 -0.07684993 -0.09923361  0.15844204 -0.13914241\n",
      " -0.04526886 -0.20045088  0.06051726  0.02802723 -0.1131601  -0.0104011\n",
      " -0.18686496 -0.09173874  0.15628007  0.12032945  0.01046313  0.08636864\n",
      " -0.01720509 -0.08132192  0.01692501  0.17351538  0.0478318   0.06502559\n",
      " -0.14855483 -0.17502968  0.06747219 -0.07226989 -0.04339044 -0.0988025\n",
      " -0.04113051  0.02528888]\n",
      "tensor_name:  layer1/dense/bias/Adam\n",
      "[-5.44827562e-05 -4.20797616e-04 -2.40355948e-04  8.08324967e-06\n",
      "  5.91609423e-05 -1.37231051e-04 -1.01638188e-05 -1.45728700e-04\n",
      "  2.19873720e-04 -2.45505507e-04 -1.76464819e-04 -5.19888883e-04\n",
      " -2.91546021e-04 -4.72305328e-06  7.25911605e-07  2.34154344e-04\n",
      " -1.33661483e-03  2.06591532e-04  1.60281430e-04 -5.55029037e-05\n",
      "  2.60560482e-04  4.35157708e-04  4.26880317e-04  6.24332635e-04\n",
      " -1.13665526e-04  3.73137125e-04 -2.94245605e-04  1.30583241e-04\n",
      "  2.53654376e-04  1.14506918e-04 -4.65909034e-05  2.86733120e-04\n",
      " -3.48326837e-04 -7.15329137e-04  1.64425583e-04 -1.72747983e-04\n",
      " -5.12415027e-05 -1.37604991e-04 -1.15685213e-08  5.98645071e-04\n",
      " -2.39519766e-04 -2.84639595e-04  5.56138577e-04  3.21856467e-04\n",
      " -8.55691687e-05 -2.98659754e-04 -1.57487171e-04  1.98002090e-04\n",
      " -5.82178182e-05 -3.29420727e-05  5.45755087e-04  3.40309867e-04\n",
      "  2.09131686e-04  3.25435307e-04  1.66905447e-05 -1.05365929e-04\n",
      " -3.33238684e-04 -3.25047469e-04  5.92324359e-05  2.87434923e-05\n",
      " -3.34689212e-05 -5.38211752e-05 -7.41843905e-07  1.23301390e-06\n",
      "  1.02340146e-05 -1.88129093e-03 -4.72279453e-07 -1.12920554e-06\n",
      " -1.49668980e-04 -5.21074107e-05  1.89899001e-04  9.53544986e-06\n",
      " -7.80984119e-05  1.37855986e-03  1.42350891e-05  1.66752521e-04\n",
      " -1.07748101e-05  6.54699106e-04 -6.98548902e-05 -1.71515800e-04\n",
      " -1.78605653e-04 -3.63767640e-07  3.14336503e-05  7.72303821e-08\n",
      "  1.23268110e-05 -7.66790690e-05  1.14866049e-37  6.21201907e-05\n",
      " -4.28776402e-05 -1.07378134e-11 -5.59228647e-04  7.53444567e-07\n",
      " -3.17482336e-05  2.14470143e-04 -3.40068538e-04 -1.22948023e-07\n",
      " -3.65788655e-05 -1.40151737e-04 -9.25235145e-06  4.84942138e-05\n",
      "  2.74613558e-04  2.72076781e-04 -3.80418423e-05 -2.43000643e-04\n",
      " -7.12541350e-06  1.22285046e-05 -1.21694975e-04 -1.04797771e-03\n",
      " -5.87494651e-05  4.61397547e-04  1.06768086e-04  1.65638179e-04\n",
      "  1.20285215e-04  3.92999995e-04  4.08367079e-04  6.79175835e-04\n",
      " -1.51586883e-05 -6.36689132e-04  1.28894626e-05  2.87719886e-05\n",
      " -2.59350549e-04 -5.53513994e-04  3.72928538e-04  1.34092849e-03\n",
      "  8.13897714e-05 -4.40230739e-04 -7.60028721e-04  5.90536583e-05\n",
      " -1.29348728e-05 -2.13526255e-06  5.71510580e-04  6.49608628e-05\n",
      "  8.93483775e-06  3.09459574e-06 -1.11385758e-04  1.01034282e-04\n",
      " -3.78004770e-05 -6.46395420e-05 -1.67033402e-04  7.37358583e-04\n",
      "  3.56188044e-04 -1.53105950e-03  2.32121007e-08  8.71863158e-05\n",
      "  3.23169189e-07 -9.54171446e-06 -2.76607534e-05 -6.35343486e-06\n",
      "  3.05637718e-06 -4.64744953e-04 -8.46584880e-05 -1.94677181e-04\n",
      "  3.51838651e-04 -9.02824013e-06 -1.60966345e-04  7.31116734e-06\n",
      " -3.00390566e-05 -1.30226777e-04  2.33867195e-05  1.75385620e-04\n",
      " -6.12513861e-04 -8.74048914e-04 -1.60587509e-03  1.50756430e-04\n",
      "  5.24302523e-05 -1.22218829e-04 -5.20244248e-05  3.48138856e-04\n",
      "  6.00724306e-05 -7.40529387e-04  3.87778156e-04  2.04104407e-11\n",
      " -7.47021841e-05  1.95351211e-04  8.35774699e-05 -1.68870232e-04\n",
      "  8.35563042e-05  4.15430812e-04  2.16071239e-05 -2.47976859e-04\n",
      "  1.56378330e-04 -7.20156604e-05  1.16156507e-03 -1.62494380e-05\n",
      " -1.95612054e-04 -4.17042000e-04  2.69628272e-05 -9.84016369e-05\n",
      "  2.58293905e-04 -1.31324459e-05  8.78559309e-04  7.40979203e-06\n",
      "  2.01204341e-04  6.48521836e-06 -1.29968487e-03  1.91067194e-03\n",
      " -5.62971458e-04 -2.18245928e-04 -1.96425826e-04 -2.51435296e-04]\n",
      "tensor_name:  layer1/dense/bias/Adam_1\n",
      "[4.86165163e-06 7.81807103e-07 2.55327564e-06 1.12102816e-05\n",
      " 2.26705015e-06 1.58838463e-06 7.09679284e-07 1.96873407e-06\n",
      " 4.98759255e-06 7.64989863e-07 1.86572493e-06 7.38439940e-06\n",
      " 2.92235586e-06 8.74695559e-07 3.16960325e-07 3.31328988e-06\n",
      " 1.04533301e-05 4.63749166e-06 5.64649008e-06 2.38995312e-06\n",
      " 2.55393820e-06 1.96528413e-06 3.91578806e-06 2.24252449e-06\n",
      " 6.62146107e-08 2.52061409e-06 1.27137855e-06 2.59819626e-06\n",
      " 9.97230700e-07 1.85412580e-06 4.31714034e-06 1.05203180e-05\n",
      " 1.19440062e-06 4.77751064e-06 1.28611146e-06 3.71023907e-06\n",
      " 2.70630153e-06 6.17184583e-07 3.14287050e-08 1.06172604e-06\n",
      " 3.89373326e-06 5.21204311e-06 2.89829791e-06 4.29253805e-06\n",
      " 8.72515102e-07 1.17678037e-05 4.90502600e-07 3.38043651e-06\n",
      " 2.68870826e-06 2.10004764e-05 7.58627084e-06 3.70825705e-06\n",
      " 1.15245791e-06 6.53751295e-06 9.82437200e-07 5.69820202e-07\n",
      " 5.45820421e-06 1.72144712e-06 8.97132679e-07 1.28524232e-06\n",
      " 1.44326361e-06 6.25566372e-07 1.49458103e-07 1.67594322e-07\n",
      " 2.43301747e-06 5.40432075e-06 3.15972045e-07 1.20568174e-07\n",
      " 7.83824817e-07 3.45274270e-06 1.54272891e-06 2.14327542e-06\n",
      " 1.12763394e-06 8.44245642e-06 1.63800428e-06 5.92967308e-06\n",
      " 2.68113786e-06 3.09666461e-06 2.48612423e-06 1.15685566e-06\n",
      " 4.32812385e-06 7.96800634e-08 3.71529973e-06 4.55735751e-08\n",
      " 5.41301733e-06 4.82692531e-06 1.63491460e-19 1.57360478e-06\n",
      " 3.33355752e-06 5.71582639e-08 2.65341532e-06 2.09357495e-07\n",
      " 3.08566155e-06 5.12229781e-06 3.61942284e-06 9.81132871e-07\n",
      " 1.59071999e-06 5.47084210e-06 6.22114612e-06 5.37997948e-06\n",
      " 4.78675747e-06 7.27137467e-06 2.49471236e-06 4.06970685e-06\n",
      " 1.11734073e-06 3.15587204e-06 5.52512620e-06 4.89856939e-06\n",
      " 2.45944989e-07 7.55717701e-06 1.87741449e-07 2.03052377e-06\n",
      " 8.40229347e-07 1.27956798e-06 8.10019174e-06 1.04120436e-05\n",
      " 4.41827842e-06 2.34253480e-06 3.56208238e-06 2.71743374e-08\n",
      " 4.37184053e-06 2.12271311e-06 4.91105175e-06 1.34823676e-05\n",
      " 2.80026461e-06 8.67435290e-07 5.51585481e-06 5.50546156e-06\n",
      " 1.23132622e-06 1.48494587e-06 6.03265335e-06 2.51558703e-07\n",
      " 1.42829867e-06 1.63089726e-06 3.94345943e-06 8.01347483e-07\n",
      " 6.58484623e-06 4.71771273e-06 1.31527258e-06 8.66870960e-06\n",
      " 9.30903025e-06 1.03097454e-05 3.02494882e-08 3.00442730e-06\n",
      " 4.79039159e-07 9.07272624e-06 7.09444294e-07 5.52345500e-06\n",
      " 1.28365468e-06 3.37333563e-06 2.59724970e-06 1.64256944e-05\n",
      " 2.79754568e-06 1.61657866e-07 1.31567299e-06 6.12169515e-07\n",
      " 4.96560858e-07 7.07200661e-06 5.00965143e-07 5.69401300e-06\n",
      " 4.54088558e-06 9.47846911e-06 8.26602354e-06 1.11484141e-07\n",
      " 6.99551629e-06 4.03588001e-06 1.41564385e-06 1.79371114e-06\n",
      " 3.87332022e-07 9.70888686e-06 6.54320843e-07 1.02019094e-07\n",
      " 2.64662140e-06 2.05105016e-06 1.88525235e-06 3.72747218e-06\n",
      " 2.87107150e-06 9.64924425e-07 1.15979810e-05 2.81449138e-06\n",
      " 4.23363190e-07 1.56211706e-06 5.06159995e-06 6.24666154e-06\n",
      " 3.35705431e-06 1.86905697e-06 1.43711998e-06 7.04317063e-06\n",
      " 7.16023578e-07 2.46320042e-06 3.90103423e-06 4.72154579e-06\n",
      " 1.22320057e-06 2.23101353e-07 8.06907246e-06 5.22934033e-06\n",
      " 3.08320296e-06 3.22052801e-06 1.16289323e-06 4.65204403e-06]\n",
      "tensor_name:  layer1/dense/kernel\n",
      "[[-0.01104958 -0.03149257  0.0609542  ...  0.04887503 -0.05664973\n",
      "   0.00778133]\n",
      " [-0.03988727 -0.0560302  -0.0709151  ... -0.02928087  0.05130166\n",
      "  -0.07581948]\n",
      " [ 0.05992617  0.02358893  0.01766432 ...  0.03194337 -0.04137886\n",
      "  -0.02968797]\n",
      " ...\n",
      " [-0.00962557 -0.06150879 -0.05601227 ... -0.03184977 -0.02179823\n",
      "   0.03371893]\n",
      " [ 0.05295402 -0.04876651  0.07415543 ...  0.05580209  0.04050494\n",
      "  -0.06941249]\n",
      " [-0.05708542  0.05524662 -0.03389598 ...  0.03212387 -0.06944697\n",
      "   0.03257002]]\n",
      "tensor_name:  layer1/dense/kernel/Adam\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "tensor_name:  layer1/dense/kernel/Adam_1\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "tensor_name:  layer2/dense/bias\n",
      "[-0.11558571  0.09058169 -0.08315166  0.00762999 -0.16256641  0.059407\n",
      " -0.1373506   0.0426135  -0.0312861  -0.14463444 -0.15023448 -0.08333541\n",
      " -0.04231432  0.19471042  0.0142457  -0.07649462 -0.01618845 -0.01857645\n",
      " -0.29718575  0.22902396 -0.07745504 -0.23306516 -0.08922563  0.03657291\n",
      " -0.2093008   0.16374703 -0.11087141  0.12805718 -0.08462771  0.17364085\n",
      " -0.056656    0.09128235  0.23873408 -0.11281198  0.08137991 -0.08874943\n",
      " -0.13552873 -0.10391781 -0.26756594  0.14439584  0.01074267 -0.06970428\n",
      " -0.05385971  0.0651945  -0.1157181   0.16931514 -0.12175827 -0.11115603\n",
      "  0.29262903  0.15616752  0.07776079  0.15312444 -0.05678846 -0.09356575\n",
      " -0.23678136 -0.0129044  -0.08016449  0.16388603  0.1960282  -0.28325146\n",
      " -0.04463179 -0.06474806  0.08578083 -0.06515187 -0.11336424 -0.08622395\n",
      "  0.08868145  0.0383815   0.07696994 -0.2125071  -0.13057317 -0.02810012\n",
      " -0.01203863 -0.05937341 -0.10478991 -0.12737718  0.06074345  0.00739238\n",
      "  0.26480037  0.01627936 -0.12363675 -0.03366195  0.03594215 -0.24935742\n",
      " -0.1462084  -0.12804866 -0.02483167  0.07835744  0.32254717  0.15120572\n",
      "  0.00095595  0.18428066 -0.0727687  -0.1690834   0.1958138   0.16420193\n",
      "  0.05448308 -0.02664462  0.0286763   0.07195365 -0.10945602  0.02477953\n",
      " -0.0919566   0.13323328  0.27585226  0.0258294  -0.07367961  0.03373705\n",
      "  0.09585148  0.06673719  0.09629219 -0.0510285  -0.16241188  0.01812022\n",
      " -0.06864497  0.1710781  -0.09474307  0.1731921  -0.1519704  -0.01157242\n",
      " -0.12081856  0.02669615 -0.09567063 -0.02466096 -0.23062211 -0.11162847\n",
      " -0.19828905  0.09101085 -0.19315381 -0.07647032 -0.22543545  0.11563712\n",
      " -0.0340097  -0.04299949  0.17002748 -0.13732259 -0.07152616 -0.04031312\n",
      " -0.04644888  0.18889    -0.05620935 -0.21184102  0.01752134 -0.16555694\n",
      "  0.00249206  0.28200766 -0.06412166 -0.14892483  0.08408982  0.23075381\n",
      "  0.16549169  0.10682657  0.2555184   0.13389541  0.2711224   0.13180871\n",
      "  0.08103024 -0.11683288  0.1400497  -0.09993865  0.05374884  0.05420165\n",
      " -0.15472963 -0.05620381 -0.07927939  0.14253685 -0.24330932  0.04850426\n",
      " -0.24553543  0.27023426 -0.0107836   0.06948327  0.10763659 -0.0681743\n",
      " -0.06174065 -0.12245593  0.3248305   0.06115509  0.22190388 -0.02896852\n",
      "  0.23314911  0.18098153  0.0605111  -0.07447179 -0.08732665 -0.12720776\n",
      "  0.09987096 -0.06148928  0.19787355  0.05754415 -0.07352457  0.27132532\n",
      " -0.03837418 -0.05203573  0.02981596  0.07617765  0.06067104  0.01260337\n",
      " -0.1587489  -0.04452389]\n",
      "tensor_name:  layer2/dense/bias/Adam\n",
      "[-5.34515057e-05  7.94904627e-05  2.57844567e-05 -1.75123932e-06\n",
      " -1.16429583e-04  1.08174048e-04  6.71340240e-05  1.22241370e-04\n",
      "  9.24129417e-05  1.05612307e-05 -1.82775373e-04 -1.44121397e-04\n",
      " -1.65538677e-05 -7.13496993e-05  1.45108526e-04 -1.21067860e-05\n",
      " -8.71111552e-05  4.83769782e-07 -5.51021840e-05  6.11679643e-05\n",
      " -2.69626689e-05 -1.51963002e-04  2.07274534e-05  9.29316084e-05\n",
      "  1.65882229e-04  3.35863762e-04  1.96101129e-04  4.24370446e-05\n",
      "  2.82587644e-06  1.03698410e-04 -7.76299785e-05 -5.44901850e-05\n",
      "  1.52573033e-04 -1.84254139e-04  2.37278728e-04 -3.18603707e-04\n",
      " -2.05954930e-05 -2.49174218e-06  1.95355788e-05  2.88293289e-04\n",
      "  2.01770512e-04 -2.61356385e-04  1.21631980e-04 -2.26458396e-05\n",
      " -1.57969844e-05  1.63589735e-04 -5.27582233e-05 -1.75059304e-05\n",
      "  2.46708281e-04 -1.14297189e-04  8.47680640e-05  1.09754968e-04\n",
      "  4.28366729e-05 -2.67311543e-06 -2.34126433e-04  1.79145973e-05\n",
      " -4.66479651e-06  1.35454713e-04  1.48035047e-04 -6.64910622e-05\n",
      "  1.40518896e-04 -1.22144809e-06  2.18930436e-05 -6.30237191e-05\n",
      " -1.11940361e-04 -9.88027386e-05 -7.02114776e-05  1.71376130e-04\n",
      " -1.53401106e-05 -2.68054777e-04 -1.44132791e-04 -6.08960072e-05\n",
      " -8.66648497e-06 -8.04507654e-05 -1.66167706e-06  8.65227503e-06\n",
      " -3.50183336e-06 -2.27081749e-04  1.95696666e-05  6.38494521e-06\n",
      " -8.52764515e-07 -2.05830525e-04 -5.47794771e-05 -2.67105002e-04\n",
      " -2.80466747e-06  2.13991698e-05  1.29725595e-06 -2.04040607e-05\n",
      "  2.73615478e-05  8.06741173e-06 -9.32630719e-05  3.36743513e-04\n",
      "  9.78114549e-05  3.11335934e-05  1.70398969e-04  1.23191057e-04\n",
      "  3.94034723e-05  3.85372841e-05 -7.61113333e-05  3.37519130e-04\n",
      " -1.57578106e-04 -2.06523153e-04  2.09244492e-04  2.91717122e-04\n",
      "  4.34782298e-04  1.24470549e-04 -9.33111005e-05  1.52509703e-04\n",
      "  1.19219054e-04 -3.29828879e-04 -7.40325340e-05  2.38640452e-04\n",
      " -1.97083151e-04  4.78852773e-04 -2.57883266e-06  4.38129064e-05\n",
      " -1.46985607e-04 -6.62988168e-05 -1.50843887e-04  7.19683303e-05\n",
      "  1.59775140e-04 -1.34038608e-04  4.28101303e-05  2.07235280e-05\n",
      " -2.94012134e-04  6.88654545e-05 -6.68086577e-05  1.13716640e-04\n",
      " -1.71594758e-04 -1.07258798e-04  5.72021600e-06 -1.36467468e-04\n",
      " -2.39849876e-04 -5.54560720e-05  2.19250156e-04 -1.03077131e-04\n",
      " -1.10737405e-04 -6.15056197e-05  1.79457911e-05 -3.67580433e-05\n",
      " -1.57534341e-05 -6.82855534e-05  8.66061237e-05 -2.28826616e-06\n",
      " -3.70543166e-05 -5.01105860e-05  1.37373194e-04 -5.39183111e-06\n",
      "  1.78631206e-04  2.86818686e-04  6.72075039e-05 -6.48241548e-05\n",
      "  6.70388865e-04  7.55579458e-05  1.52425637e-04 -3.40989645e-05\n",
      "  7.84907024e-05 -5.79074076e-05 -1.25705003e-04 -1.26537852e-05\n",
      "  9.13177792e-05  2.54948827e-05 -3.89305023e-05 -3.40274964e-05\n",
      " -2.96426646e-04 -3.43903121e-05 -1.27269723e-05 -7.89716069e-07\n",
      " -6.20826177e-05  3.25132656e-04 -2.53468843e-05 -1.95201166e-04\n",
      "  4.86790348e-04  1.48361913e-04 -1.00054785e-04  7.18969750e-05\n",
      "  6.85687410e-05  6.48514178e-05  4.91085157e-05 -1.00521880e-04\n",
      " -9.89114596e-06  1.61172997e-04  3.94415365e-05 -6.61509603e-06\n",
      " -2.13966603e-04  6.23899450e-06 -1.39291995e-04 -3.85155909e-06\n",
      "  1.99429196e-04 -6.29725946e-06 -2.79348838e-04  6.64858162e-05\n",
      " -4.52379572e-05  1.59466479e-04  9.70823862e-07 -9.69899120e-05\n",
      "  7.04945123e-05 -2.47033924e-04 -4.71498424e-05  4.82808809e-06]\n",
      "tensor_name:  layer2/dense/bias/Adam_1\n",
      "[6.9579045e-07 1.8626395e-07 1.8394071e-07 4.3565358e-08 3.6896586e-07\n",
      " 3.3626719e-07 5.7966071e-07 4.1599452e-07 4.4265079e-07 4.1415700e-07\n",
      " 7.8194392e-07 8.3536275e-07 8.1755519e-07 2.5054612e-07 1.3405962e-07\n",
      " 2.9183707e-07 7.4404329e-07 2.2332159e-07 8.9521262e-07 1.6158680e-07\n",
      " 3.7190637e-07 4.5503870e-07 3.4573497e-07 2.6004724e-07 3.7656062e-07\n",
      " 2.3375040e-07 1.9887190e-07 6.0080424e-07 1.3398721e-06 6.0178394e-07\n",
      " 4.0008675e-07 2.9573653e-07 3.3489340e-07 3.7873750e-07 2.8751384e-07\n",
      " 4.6915937e-07 1.4399599e-07 2.5943510e-07 5.9999718e-07 7.7546753e-07\n",
      " 8.9447803e-07 1.2408267e-07 6.7773648e-08 1.4062259e-07 7.8018979e-07\n",
      " 1.8915031e-07 7.1622532e-07 6.0116498e-08 4.8263450e-07 5.2116218e-07\n",
      " 6.1962811e-07 4.0691401e-07 4.8087651e-07 1.5003546e-07 4.0375588e-07\n",
      " 2.8535058e-07 1.7073289e-07 2.5445624e-07 1.1782427e-06 9.3586408e-08\n",
      " 6.0662956e-07 7.2477369e-10 3.3769555e-07 3.3057003e-07 2.7311913e-07\n",
      " 2.5036914e-07 9.3359702e-08 2.7999175e-07 5.9454231e-07 1.0114718e-06\n",
      " 6.9393474e-07 9.9075116e-08 1.2799549e-07 7.4994256e-07 2.5891101e-08\n",
      " 1.7896207e-07 8.4500158e-08 1.1861731e-06 9.6382007e-07 1.5910889e-07\n",
      " 1.3372002e-07 4.8010355e-07 1.6695222e-07 6.4526404e-07 1.2471756e-07\n",
      " 2.0799051e-07 4.6686355e-07 3.2265089e-07 2.4570346e-07 3.2248892e-08\n",
      " 7.6470963e-07 5.7740664e-07 6.5425814e-07 5.1937252e-07 2.6790391e-07\n",
      " 4.2910287e-07 2.9586278e-07 3.0389461e-07 3.6193489e-07 2.0107963e-07\n",
      " 2.3570577e-07 4.9618211e-07 7.3162352e-07 9.3076568e-07 3.8239426e-07\n",
      " 4.1922416e-07 2.5847632e-07 7.1293766e-07 3.3182729e-07 1.0114236e-06\n",
      " 4.6194452e-07 5.3376618e-07 3.0652407e-07 3.9531469e-07 3.4828946e-07\n",
      " 3.3477372e-07 1.3561861e-07 4.2446831e-07 2.1357883e-07 7.5028828e-07\n",
      " 7.0629795e-07 6.2055364e-07 5.0015035e-07 5.3040431e-08 8.8342625e-07\n",
      " 4.5052181e-07 1.5921640e-07 2.6779364e-07 3.4064698e-07 6.2607631e-07\n",
      " 6.3549390e-07 3.3385513e-07 4.9637725e-07 6.1038577e-07 4.5707617e-07\n",
      " 1.6600374e-07 3.3557552e-07 1.7660122e-07 2.7138194e-07 1.8217128e-07\n",
      " 7.6720234e-08 4.1116297e-07 1.2826229e-07 4.8048122e-07 3.9387334e-07\n",
      " 5.8101313e-07 9.5290339e-08 7.8307288e-08 4.8617989e-07 5.6688759e-07\n",
      " 1.5946010e-07 5.5937517e-07 5.5650622e-07 4.9191062e-08 3.2051264e-07\n",
      " 4.2568379e-07 4.8165742e-07 3.1776383e-07 6.1625406e-07 1.4122188e-07\n",
      " 2.7267131e-07 5.9363015e-07 5.8133224e-07 2.2826839e-07 1.1689434e-06\n",
      " 4.9339934e-07 5.8233343e-07 2.1300717e-07 1.1350484e-07 5.8783712e-07\n",
      " 5.3730690e-07 1.4429060e-07 3.1537078e-07 8.0612544e-08 2.9495166e-07\n",
      " 8.6476371e-07 6.8942677e-07 2.8947653e-07 3.8746444e-07 2.1755326e-07\n",
      " 2.6027462e-07 3.6309171e-07 3.7906992e-07 2.6209815e-07 1.3317774e-06\n",
      " 5.9629411e-07 2.1729153e-07 1.5312744e-07 8.4950170e-07 2.0013809e-07\n",
      " 3.9530644e-07 5.1734651e-07 3.3349608e-07 5.3586734e-07 7.2262281e-08\n",
      " 2.2795497e-07 9.3783603e-07 2.2415625e-07 6.4672025e-07 1.3427241e-07]\n",
      "tensor_name:  layer2/dense/kernel\n",
      "[[ 0.36614728  0.20570529  0.43382955 ...  0.04797387  0.15950726\n",
      "   0.12226217]\n",
      " [-0.2748479  -0.13708465  0.09163236 ... -0.09663303  0.22604555\n",
      "  -0.03382145]\n",
      " [-0.07426097  0.10903553  0.0331796  ...  0.16236709  0.02590821\n",
      "  -0.00506141]\n",
      " ...\n",
      " [-0.02304759  0.08417531 -0.2585045  ...  0.29080573 -0.04504623\n",
      "   0.07866569]\n",
      " [-0.12516186 -0.14048299 -0.03712773 ... -0.17104931  0.16704078\n",
      "   0.22409876]\n",
      " [-0.02458612 -0.05308476 -0.03185492 ...  0.1882122   0.06765977\n",
      "  -0.12357881]]\n",
      "tensor_name:  layer2/dense/kernel/Adam\n",
      "[[-1.1619628e-06 -1.5382571e-05 -7.5974560e-07 ... -6.6334096e-06\n",
      "   3.8655135e-06  6.3705556e-09]\n",
      " [-3.8480556e-07 -2.7921758e-05  4.9785200e-07 ... -5.6778921e-05\n",
      "  -2.5450058e-06 -1.1920821e-05]\n",
      " [-1.1676671e-06 -2.0341999e-05 -4.7212797e-08 ... -1.3639421e-04\n",
      "  -5.9986378e-05 -3.4884713e-05]\n",
      " ...\n",
      " [-2.1819437e-06  3.3456523e-05  2.1805619e-07 ... -1.5175049e-04\n",
      "   2.5786842e-06 -9.7321092e-08]\n",
      " [-7.5940548e-06  1.7773973e-04  2.5288129e-09 ...  1.1099769e-05\n",
      "   3.1409206e-06 -2.4315616e-06]\n",
      " [ 1.0425538e-04 -1.9183211e-05  2.0792711e-05 ... -4.3392350e-04\n",
      "  -6.7649220e-05 -2.4148696e-07]]\n",
      "tensor_name:  layer2/dense/kernel/Adam_1\n",
      "[[1.4138158e-06 4.1357384e-07 4.4313148e-07 ... 3.6550435e-07\n",
      "  3.8597867e-07 2.4435988e-07]\n",
      " [1.3707231e-07 8.5035396e-08 1.1393228e-07 ... 5.8259140e-08\n",
      "  3.7283169e-07 8.2847990e-08]\n",
      " [7.3637216e-07 6.5057822e-07 3.5355103e-07 ... 4.6014978e-07\n",
      "  6.3606387e-07 1.7226847e-07]\n",
      " ...\n",
      " [2.8053825e-07 8.0991207e-08 1.1944813e-08 ... 1.0344958e-07\n",
      "  2.2253842e-07 4.4476756e-08]\n",
      " [5.5437067e-07 4.3096526e-07 1.4879407e-07 ... 2.3026841e-07\n",
      "  1.4016966e-06 1.6534928e-07]\n",
      " [7.7903695e-07 1.5798565e-07 5.3096846e-07 ... 1.0481426e-06\n",
      "  7.6142845e-07 8.1889617e-08]]\n",
      "tensor_name:  logits_layer/dense/bias\n",
      "[-0.05765572 -0.18095502 -0.04650183 -0.05745185 -0.03124258 -0.04452137\n",
      " -0.13558002 -0.16484576  0.42624772  0.10935257]\n",
      "tensor_name:  logits_layer/dense/bias/Adam\n",
      "[-4.5763180e-05 -1.9107505e-05 -2.1137786e-05 -4.6542790e-04\n",
      "  1.5179301e-04 -6.4053328e-04  3.9164737e-04 -1.6866997e-04\n",
      "  7.5214636e-04  6.5054817e-05]\n",
      "tensor_name:  logits_layer/dense/bias/Adam_1\n",
      "[1.0089664e-06 2.1451908e-06 1.9473723e-06 2.4935161e-06 2.9803180e-06\n",
      " 2.3523776e-06 1.6804019e-06 3.1122031e-06 2.8640782e-06 4.0347450e-06]\n",
      "tensor_name:  logits_layer/dense/kernel\n",
      "[[-0.19427562 -0.18179384  0.13797748 ...  0.27703214 -0.1689119\n",
      "  -0.46528447]\n",
      " [-0.40990975  0.11680367  0.07017844 ...  0.03051657  0.20286427\n",
      "   0.02408654]\n",
      " [-0.17962374  0.06002008 -0.02140728 ... -0.03910252 -0.43263668\n",
      "   0.14797798]\n",
      " ...\n",
      " [-0.41982755  0.07243734  0.06284358 ...  0.01127103  0.11741241\n",
      "   0.03728186]\n",
      " [ 0.24894023 -0.28543746  0.15427792 ...  0.1968549  -0.33184695\n",
      "  -0.46435913]\n",
      " [ 0.1488057  -0.31954363 -0.18749233 ...  0.13422595 -0.19182199\n",
      "   0.18856211]]\n",
      "tensor_name:  logits_layer/dense/kernel/Adam\n",
      "[[ 9.66679977e-07  7.51030211e-06 -7.91943094e-05 ... -6.85425301e-04\n",
      "   2.51839374e-05  7.58957933e-04]\n",
      " [-1.13328446e-04  2.73041269e-06 -9.63457933e-06 ...  9.27748715e-06\n",
      "   3.75248166e-03  2.77194104e-05]\n",
      " [ 1.79663672e-07  2.22809558e-06  1.28647935e-05 ... -6.51870187e-06\n",
      "   5.47288391e-06 -6.17374462e-05]\n",
      " ...\n",
      " [-1.54589688e-05  5.46338470e-06 -1.95342782e-05 ... -3.16611549e-05\n",
      "   1.80138368e-03  9.43104824e-05]\n",
      " [-4.02881451e-05 -3.11746189e-05 -4.28942767e-05 ... -8.80968000e-05\n",
      "   4.01961879e-05  5.02939247e-06]\n",
      " [-4.69508677e-06  1.83315774e-06 -1.70842509e-06 ... -1.30287124e-04\n",
      "   5.79876360e-06  8.12158760e-05]]\n",
      "tensor_name:  logits_layer/dense/kernel/Adam_1\n",
      "[[5.4463453e-07 2.8910370e-06 4.5455827e-06 ... 5.7599063e-06\n",
      "  2.8094234e-06 3.0124836e-06]\n",
      " [4.2071554e-07 2.8774809e-06 4.2802621e-06 ... 1.3577873e-06\n",
      "  1.8547578e-05 4.2858751e-06]\n",
      " [1.4052833e-07 2.9884079e-06 4.2232400e-06 ... 7.8641301e-07\n",
      "  1.0866985e-06 2.8163536e-06]\n",
      " ...\n",
      " [1.7831111e-07 2.9068308e-06 7.0528663e-06 ... 8.9605401e-06\n",
      "  1.2263538e-05 8.9703090e-06]\n",
      " [6.1777878e-06 4.7237950e-06 1.2838241e-05 ... 2.8254459e-05\n",
      "  3.0462616e-06 6.9767007e-06]\n",
      " [1.4331600e-06 1.3558355e-07 2.1214434e-07 ... 1.2637501e-05\n",
      "  9.2116409e-07 1.2852789e-05]]\n"
     ]
    }
   ],
   "source": [
    "# import the inspect_checkpoint library\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "# print all tensors in checkpoint file\n",
    "chkp.print_tensors_in_checkpoint_file(tf.train.latest_checkpoint('./mnist/'), tensor_name='', all_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./mnist/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.04025666 0.10458057 0.10845653 0.10694748 0.08592811 0.0421818\n",
      "  0.06704649 0.21724518 0.07609104 0.15126604]]\n",
      "INFO:tensorflow:loss = 1.5267287, step = 2\n",
      "INFO:tensorflow:Loss for final step: 1.5267287.\n",
      "CPU times: user 719 ms, sys: 33.5 ms, total: 752 ms\n",
      "Wall time: 739 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train_},\n",
    "    y=y_train,\n",
    "    batch_size=1,\n",
    "    num_epochs=None,\n",
    "    shuffle=False\n",
    ")\n",
    "classifier.train(input_fn=train_input_fn, steps=1, hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-29-01:28:58\n",
      "INFO:tensorflow:Restoring parameters from mnist/model.ckpt-23613\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-29-01:28:59\n",
      "INFO:tensorflow:Saving dict for global step 23613: accuracy = 0.9832, global_step = 23613, loss = 0.1050892\n",
      "{'accuracy': 0.9832, 'loss': 0.1050892, 'global_step': 23613}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test_},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt-23613\n",
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt-23613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(199210,\n",
       " array([-0.03311902, -0.14471869, -0.1002543 , -0.02374201, -0.01721681],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_weights_as_np():\n",
    "    tf.reset_default_graph()\n",
    "    weights = []\n",
    "    with tf.Session().as_default() as sess:\n",
    "        new_saver = tf.train.import_meta_graph(tf.train.latest_checkpoint('./mnist/') + '.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./mnist/'))\n",
    "        collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        weights = {tensor.name:sess.run(tensor) for tensor in collection}\n",
    "    return weights\n",
    "        \n",
    "weights = export_weights_as_np(Perceptron, hparams)\n",
    "weights2 = export_weights_as_np(Perceptron, hparams)\n",
    "sum(w.size for _, w in weights.items()), weights['layer1/dense/bias:0'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06623803, -0.28943738, -0.20050861, -0.04748401, -0.03443361],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = {}\n",
    "for key1, key2 in zip(sorted(weights.keys()), sorted(weights2.keys())):\n",
    "    assert key1 == key2, 'Error with keys'\n",
    "    new_weights[key1] = weights[key1] + weights2[key2]\n",
    "new_weights['layer1/dense/bias:0'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt\n",
      "Model saved in path: ./mnist/model.ckpt-1337\n"
     ]
    }
   ],
   "source": [
    "def load_weights(weights, round_num):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session().as_default() as sess:\n",
    "        new_saver = tf.train.import_meta_graph(tf.train.latest_checkpoint('./mnist/') + '.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./mnist/')) # to load non-trainable variables \n",
    "        \n",
    "        collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        for tensor in collection:\n",
    "            assign_op = tensor.assign(weights[tensor.name])\n",
    "            sess.run(assign_op)\n",
    "        \n",
    "        save_path = new_saver.save(sess, \"./mnist/model.ckpt\", global_step=round_num)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "load_weights(new_weights, 1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"node\": [\\n    {\\n      \"name\": \"Placeholder\",\\n '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.protobuf import json_format\n",
    "\n",
    "def export_metagraph_as_json(model, hparams):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        m = model(hparams)\n",
    "        m.build_model(tf.placeholder(tf.float32, (None, 28*28)))\n",
    "        m.build_predictions_obj()\n",
    "        graph_def = graph.as_graph_def()\n",
    "        json_string = json_format.MessageToJson(graph_def)\n",
    "    return json_string\n",
    "\n",
    "export_metagraph_as_json(Perceptron, hparams)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mnist/model.ckpt-23613'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def export_metagraph():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session().as_default() as sess:\n",
    "        new_saver = tf.train.import_meta_graph(tf.train.latest_checkpoint('./mnist/') + '.meta')\n",
    "#         m = model(hparams)\n",
    "#         m.build_model(tf.placeholder(tf.float32, (None, 28*28), name='input_tensor'))\n",
    "#         m.build_predictions_obj()\n",
    "        meta_graph_def = tf.train.export_meta_graph()\n",
    "    return meta_graph_def\n",
    "\n",
    "#mgraph = export_metagraph()\n",
    "#metagraph = export_metagraph(Perceptron, hparams)\n",
    "tf.train.latest_checkpoint('./mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist/model.ckpt-23613\n",
      "[<tf.Variable 'global_step:0' shape=() dtype=int64_ref>, <tf.Variable 'layer1/dense/kernel:0' shape=(784, 200) dtype=float32_ref>, <tf.Variable 'layer1/dense/bias:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'layer2/dense/kernel:0' shape=(200, 200) dtype=float32_ref>, <tf.Variable 'layer2/dense/bias:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/kernel:0' shape=(200, 10) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/bias:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'layer1/dense/kernel/Adam:0' shape=(784, 200) dtype=float32_ref>, <tf.Variable 'layer1/dense/kernel/Adam_1:0' shape=(784, 200) dtype=float32_ref>, <tf.Variable 'layer1/dense/bias/Adam:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'layer1/dense/bias/Adam_1:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'layer2/dense/kernel/Adam:0' shape=(200, 200) dtype=float32_ref>, <tf.Variable 'layer2/dense/kernel/Adam_1:0' shape=(200, 200) dtype=float32_ref>, <tf.Variable 'layer2/dense/bias/Adam:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'layer2/dense/bias/Adam_1:0' shape=(200,) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/kernel/Adam:0' shape=(200, 10) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/kernel/Adam_1:0' shape=(200, 10) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/bias/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'logits_layer/dense/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]\n",
      "Tensor(\"enqueue_input/Placeholder_1:0\", dtype=float32, device=/device:CPU:0)\n",
      "Tensor(\"logits_layer/dense/BiasAdd:0\", shape=(100, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def build_latest_graph():\n",
    "    tf.reset_default_graph()\n",
    "    loaded_graph = tf.Graph()\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        #new_saver = tf.train.import_meta_graph(metagraph)\n",
    "        new_saver = tf.train.import_meta_graph(tf.train.latest_checkpoint('./mnist/') + '.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./mnist/'))\n",
    "        \n",
    "        print(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "        \n",
    "        input = loaded_graph.get_tensor_by_name('enqueue_input/Placeholder_1:0')\n",
    "        #input = loaded_graph.get_collection('enqueue_input')\n",
    "        #input = loaded_graph.get_collection('input_tensor:0')\n",
    "        print(input)\n",
    "        \n",
    "        logits, classes, probabilities = loaded_graph.get_collection('predictions')\n",
    "        print(logits)\n",
    "        \n",
    "#         def get_model(features, labels, mode):\n",
    "#             return tf.estimator.EstimatorSpec(mode=mode, predictions=classes)\n",
    "            \n",
    "        \n",
    "#         hparams = {'learning_rate': 0.001}\n",
    "#         model = Perceptron(hparams)\n",
    "#         classifier = tf.estimator.Estimator(model_fn=get_model, model_dir=\"mnist2/\")\n",
    "#         # Evaluate the model and print results\n",
    "#         eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#             x={\"x\": X_test_},\n",
    "#             y=y_test,\n",
    "#             num_epochs=1,\n",
    "#             shuffle=False\n",
    "#         )\n",
    "#         eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "#         print(eval_results)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         pred = sess.run(classes, feed_dict={input: X_test_[:10]})\n",
    "#         print(pred, y_test[:10])\n",
    "        \n",
    "        #print(sess.run(predictions[0]))\n",
    "    #print(sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)))\n",
    "    #   for step in xrange(1000000):\n",
    "    #     sess.run(train_op)\n",
    "\n",
    "build_latest_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "m = Perceptron(hparams)\n",
    "m.build_model(tf.placeholder(tf.float32, (None, 28*28)))\n",
    "\n",
    "weights = []\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  #new_saver = tf.train.import_meta_graph('mnist/model.ckpt-23605.meta')\n",
    "  #new_saver.restore(sess, tf.train.latest_checkpoint('mnist'))\n",
    "  #saver.restore(sess, \"./mnist/model.ckpt\") \n",
    "    \n",
    "  ckpt = tf.train.get_checkpoint_state(\"./mnist/model.ckpt-23604\")\n",
    "  print(ckpt)\n",
    "  \n",
    "    \n",
    "  print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "  weights = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_model() missing 1 required positional argument: 'input_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d61c059f5c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-d61c059f5c71>\u001b[0m in \u001b[0;36mprepare_for_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./mnist/lol.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-9ee8d2d9546e>\u001b[0m in \u001b[0;36mbuild_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: build_model() missing 1 required positional argument: 'input_layer'"
     ]
    }
   ],
   "source": [
    "def prepare_for_training():\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session().as_default() as sess:\n",
    "        m = Perceptron(hparams)\n",
    "        m.build_all()\n",
    "        tf.train.import_meta_graph(filename='./mnist/lol.meta')\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "prepare_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mnist/model.ckpt-2'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('./mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
